{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f9421ac-850d-4929-995d-95785808f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import rank, col, monotonically_increasing_id, row_number,min\n",
    "import os\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f69af16a-28ef-4c3e-bf76-18d722897797",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'input-data-set/Inventory_Management_Src1.csv'\n",
    "\n",
    "# input_file_path = os.path.join(script_dir, relative_path)\n",
    "\n",
    "# Initialize Spark session\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "401aab0e-6e61-4bf8-bffe-818cb64dc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Star Schema\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca85a9f-da8b-49a9-9070-353b0999a74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd36b830-2707-4deb-99fe-e34f13e79cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "except Exception as e:\n",
    "    print(\"an error was occured reading the main input file \" )\n",
    "    print( \"ERROR: \" , e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c9c8ff6-c28b-4a46-8fc0-c0d7e715f6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output folder and handle the case when output does not exist\n",
    "\n",
    "output_dir = \"output\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f1eed7b-cfd1-469b-b93e-233218d68644",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+-----------------+-----------------------+-------------+--------------+------------+-----------------+---------------+\n",
      "|CUSTOMER_ID|     Customer Name|CUSTOMER_LOGIN_ID|CUSTOMER_STREET_ADDRESS|CUSTOMER_CITY|CUSTOMER_STATE|CUSTOMER_ZIP|CUSTOMER_PHONE_NO|CUSTOMER_DIM_ID|\n",
      "+-----------+------------------+-----------------+-----------------------+-------------+--------------+------------+-----------------+---------------+\n",
      "|     100078|     Caldwell Wade|             5078|   216-4377 Semper, St.|     COLUMBUS|          OHIO|       94154|     027-779-9608|              1|\n",
      "|     100003|       Fritz Grant|             5003|   Ap #897-7736 Eges...| PHILADELPHIA|  PENNSYLVANIA|       65342|     029-197-3614|              2|\n",
      "|     100082|    Graiden Oneill|             5082|   P.O. Box 708, 751...|       BOSTON|MASSAACHUSETTS|       95485|     011-485-6145|              3|\n",
      "|     100040|       Caryn Doyle|             5040|      3258 Massa Avenue|     NEW YORK|       NEWYORK|       92424|     090-909-0118|              4|\n",
      "|     100005|      Tatyana Ball|             5005|   Ap #422-2469 Eget...|      HOUSTON|         TEXAS|       63842|     093-567-5411|              5|\n",
      "|     100097|   Ignatius Mercer|             5097|   366-698 Auctor, A...|      PHOENIX|       ARIZONA|       98187|     017-928-0125|              6|\n",
      "|     100083|   Danielle Wilcox|             5083|   7967 Lobortis. St...| PHILADELPHIA|  PENNSYLVANIA|       84107|     025-225-3040|              7|\n",
      "|     100010|    Clio Middleton|             5010|   P.O. Box 780, 390...| PHILADELPHIA|  PENNSYLVANIA|       63859|     075-516-4398|              8|\n",
      "|     100022|     Angelica Lamb|             5022|   AP #580-4729 Cras...|     COLUMBUS|          OHIO|       53848|     065-434-0244|              9|\n",
      "|     100084|      Ebony Durham|             5084|           9214 Ac, Ave|    SAN DIEGO|    CALIFORNIA|       76584|     003-620-6495|             10|\n",
      "|     100024|    Dora Zimmerman|             5024|   Ap #386-1113 Dign...|      CHICAGO|      ILLINOIS|       73494|     003-363-9672|             11|\n",
      "|     100057|      Edward Lopez|             5057|   P.O. Box 523, 732...|      PHOENIX|       ARIZONA|       53765|     032-378-8856|             12|\n",
      "|     100021|       Nora Stuart|             5021|     7794 Elementum Av.|      HOUSTON|         TEXAS|       79987|     008-962-2784|             13|\n",
      "|     100072|     Ayanna Riddle|             5072|   Ap #865-2255 Viva...|     COLUMBUS|          OHIO|       96602|     069-671-4776|             14|\n",
      "|     100015|  Timothy Mcdonald|             5015|   P.O. Box 972, 404...|    SAN DIEGO|    CALIFORNIA|       59167|     019-408-7488|             15|\n",
      "|     100045|    Darryl Ramirez|             5045|         425-9230 A Av.|  Los Angeles|    California|       72180|     013-892-4548|             16|\n",
      "|     100002|  Chantale Gardner|             5002|           9257 Et, Rd.|  LOS ANGELES|    CALIFORNIA|       58854|     063-786-7948|             17|\n",
      "|     100058|      Chase Alston|             5058|   P.O. Box 389,2586...|SAN FRANSISCO|    California|       71401|     066-278-8493|             18|\n",
      "|     100098|       Shaine Good|             5098|   P.O. Box 161, 468...|    SAN DIEGO|    CALIFORNIA|       71455|     057-662-4801|             19|\n",
      "|     100032|Clinton Valenzuela|             5032|     8114 Imperdiet Av.|  Los Angeles|    California|       61854|     007-980-5252|             20|\n",
      "+-----------+------------------+-----------------+-----------------------+-------------+--------------+------------+-----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Customers Dimension Table\n",
    "try:\n",
    "    customers_df = df.select(\"CUSTOMER_ID\", \"Customer Name\", \"CUSTOMER_LOGIN_ID\", \n",
    "                         \"CUSTOMER_STREET_ADDRESS\", \"CUSTOMER_CITY\", \"CUSTOMER_STATE\", \n",
    "                         \"CUSTOMER_ZIP\", \"CUSTOMER_PHONE_NO\").dropDuplicates()\n",
    "    \n",
    "    windowSpec = Window.orderBy(monotonically_increasing_id())\n",
    "    customers_dim = customers_df.withColumn(\"CUSTOMER_DIM_ID\", row_number().over(windowSpec))\n",
    "    \n",
    "    # show Customers Dimension table\n",
    "    customers_dim.show() \n",
    "except Exception as e:\n",
    "    print(\"an error was occured while creating cutomers dimension table \" )\n",
    "    print( \"ERROR: \" , e)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "213a5004-70e7-4d46-a046-9cdd1ca30ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing to pandas (to save file in csv)\n",
    "try:\n",
    "    customers_dim_pandas = customers_dim.toPandas()\n",
    "    \n",
    "    # handling the path not found errors \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Now save to CSV in the 'output' folder\n",
    "    customers_dim_pandas.to_csv(f\"{output_dir}/customers_dim.csv\", index=False)\n",
    "except Exception as e:\n",
    "    print(\"an error was occured while writing(saving) cutomers dimension table \" )\n",
    "    print( \"ERROR: \" , e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e8b8ad94-6d83-4507-978a-786778228469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+------------+-------------+----------------+-------------+--------------+\n",
      "|PRODUCT_ID|CATEGORY_ID|PRODUCT Name|PRODUCT Brand|Product Model No|PRODUCT_STOCK|PRODUCT_DIM_ID|\n",
      "+----------+-----------+------------+-------------+----------------+-------------+--------------+\n",
      "|      3005|       4005|      LAPTOP|           HP|            4620|            1|             1|\n",
      "|      3093|       4005|      LAPTOP|      TOSHIBA|            4978|            1|             2|\n",
      "|      3047|       4004|  TELEVISION|      PHILIPS|            4500|            0|             3|\n",
      "|      3073|       4006|    PENDRIVE|      SANDISK|            9457|            1|             4|\n",
      "|      3033|       4007|   EARPHONES|         SONY|           11456|            1|             5|\n",
      "|      3022|       4004|  TELEVISION|           LG|            4950|            1|             6|\n",
      "|      3094|       4006|    PENDRIVE|     KINGSTON|            9965|            0|             7|\n",
      "|      3074|       4007|   EARPHONES|        BEATS|           11446|            0|             8|\n",
      "|      3015|       4002|         BAG|         PUMA|           31330|            0|             9|\n",
      "|      3086|       4004|  TELEVISION|      SAMSUNG|            4445|            1|            10|\n",
      "|      3081|       4007|   EARPHONES|        BEATS|           17890|            0|            11|\n",
      "|      3069|       4007|   EARPHONES|         BOSE|           11460|            0|            12|\n",
      "|      3054|       4006|    PENDRIVE|    MOSERBAER|            9750|            1|            13|\n",
      "|      3039|       4007|   EARPHONES|          JBL|           11450|            1|            14|\n",
      "|      3072|       4008|  DVD PLAYER|        ONIDA|            2360|            1|            15|\n",
      "|      3080|       4001|       SHOES|       REEBOK|           21340|            1|            16|\n",
      "|      3079|       4001|       SHOES|       REEBOK|           24580|            0|            17|\n",
      "|      3017|       4008|  DVD PLAYER|        ONIDA|            2800|            0|            18|\n",
      "|      3025|       4000|      CAMERA|        SONY |            1760|            0|            19|\n",
      "|      3056|       4005|      LAPTOP|         DELL|            4789|            1|            20|\n",
      "+----------+-----------+------------+-------------+----------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# product dimension table \n",
    "\n",
    "try:\n",
    "\n",
    "    products_df = df.select(\"PRODUCT_ID\", \"CATEGORY_ID\", \"PRODUCT Name\", \"PRODUCT Brand\", \n",
    "                            \"Product Model No\", \"PRODUCT_STOCK\").dropDuplicates()\n",
    "    \n",
    "    products_df = df.groupby(\"PRODUCT_ID\", \"CATEGORY_ID\", \"PRODUCT Name\", \"PRODUCT Brand\", \n",
    "                            \"Product Model No\").agg(min(col(\"PRODUCT_STOCK\")).alias(\"PRODUCT_STOCK\"))\n",
    "    \n",
    "    products_dim = products_df.withColumn(\"PRODUCT_DIM_ID\", row_number().over(windowSpec))\n",
    "    \n",
    "    # show  Products Dimension table\n",
    "    products_dim.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"an error was occured while creating product dimension table \" )\n",
    "    print( \"ERROR: \" , e)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b7d31d3f-bbc9-4dcf-b479-9f939e7d9fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing to pandas and saving as csv file\n",
    "try:\n",
    "    products_dim_pandas = products_dim.toPandas()\n",
    "    products_dim_pandas.to_csv(f\"{output_dir}/products_dim.csv\", index=False)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"an error was occured while saving(writing) product dimension table \" )\n",
    "    print( \"ERROR: \" , e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e09a075-0a95-4a58-866c-a55852cba4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+-------------+---------------------+-----------+--------------------+----------+---------------+-------------+\n",
      "|SELLER_ID|     SELLER_NAME|SELLER_RATING|SELLER_STREET_ADDRESS|SELLER_CITY|        SELLER_STATE|SELLER_ZIP|SELLER_PHONE_NO|SELLER_DIM_ID|\n",
      "+---------+----------------+-------------+---------------------+-----------+--------------------+----------+---------------+-------------+\n",
      "|   200046|    Leroy Conner|            5| P.O. Box 965, 585...|      BREST|            BRITTANY|     76254| 08 90 52 61 56|            1|\n",
      "|   200020|   Basia Nielsen|            4| Ap #755-3390 Semp...|      TOURS|              CENTRE|     80874| 03 11 73 89 94|            2|\n",
      "|   200091|    Leo Atkinson|            4|  134-8687 Primis St.|      BREST|            BRITTANY|     81059| 06 56 07 84 00|            3|\n",
      "|   200089|  Deborah Wooten|            5|      7708 Lorem, Rd.|       LYON|         RHONE-ALPES|     58575| 01 15 87 00 65|            4|\n",
      "|   200011|   Jescie Kelley|            2|       2332 Risus Ave|   LE  MANS|    PAYS DE LA LOIRE|     79306| 05 97 51 95 35|            5|\n",
      "|   200010|    Bert Delgado|            1| P.O. Box 300, 879...|      NIMES|LANGUEDOC-ROUSSILLON|     94978| 02 36 21 21 68|            6|\n",
      "|   200038|        Bo Curry|            2|  392-5160 At, Street|      DIJON|           BOURGOGNE|     73038| 05 34 20 09 53|            7|\n",
      "|   200018|       Cara Mays|            5| P.O. Box 672, 698...|   GRENOBLE|         RHONE-ALPES|     72207| 02 62 79 33 75|            8|\n",
      "|   200025|      Zia Jacobs|            1|   142-2259 Eros. St.|      NIMES|LANGUEDOC-ROUSSILLON|     73940| 04 06 38 68 77|            9|\n",
      "|   200083|      Elmo Cross|            1|        1080 Dui, St.|   GRENOBLE|         RHONE-ALPES|     83608| 01 44 53 77 56|           10|\n",
      "|   200049|Cherokee Richard|            5| Ap #381-3851 Eget...|      PARIS|       ILE-DE-FRANCE|     72816| 01 33 96 49 60|           11|\n",
      "|   200078|      Eve Coffey|            5|  328-4434 Nec Avenue|       CAEN|     BASSE-NORMANDIE|     94198| 04 73 32 75 53|           12|\n",
      "|   200093|  Palmer Simpson|            2|    3966 Donec Street|      DIJON|           BOURGOGNE|     73506| 05 58 68 70 12|           13|\n",
      "|   200055|   Vernon George|            2| 164-9024 Mollis S...|       METZ|            LORRAINE|     77588| 01 86 75 94 18|           14|\n",
      "|   200071|   Octavia Blair|            5| P.O. Box 237, 257...|      PARIS|       ILE-DE-FRANCE|     79555| 08 03 10 94 17|           15|\n",
      "|   200023|    Akeem Guerra|            1| Ap #586-1460 Temp...|       LYON|         RHONE-ALPES|     68382| 01 63 70 67 55|           16|\n",
      "|   200070|  Stacey Solomon|            4| P.O. Box 643, 497...|       CAEN|     BASSE-NORMANDIE|     77610| 07 82 17 55 75|           17|\n",
      "|   200026| Shoshana Tanner|            2|      126-1135 Id Rd.|      TOURS|              CENTRE|     75729| 08 43 18 18 46|           18|\n",
      "|   200075|  Chelsea Nguyen|            2|      326-6500 A Road|      TOURS|              CENTRE|     68375| 06 27 14 55 56|           19|\n",
      "|   200069|     Rina Malone|            1| 565-9093 Tellus, Av.|      TOURS|              CENTRE|     64702| 01 77 01 21 34|           20|\n",
      "+---------+----------------+-------------+---------------------+-----------+--------------------+----------+---------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create Seller Dimension Table\n",
    "try:\n",
    "    sellers_df = df.select(\"SELLER_ID\", \"SELLER_NAME\", \"SELLER_RATING\", \"SELLER_STREET_ADDRESS\", \n",
    "                           \"SELLER_CITY\", \"SELLER_STATE\", \"SELLER_ZIP\", \"SELLER_PHONE_NO\").dropDuplicates()\n",
    "    \n",
    "    sellers_dim = sellers_df.withColumn(\"SELLER_DIM_ID\", row_number().over(windowSpec))\n",
    "    \n",
    "    # show Seller Dimension table\n",
    "    sellers_dim.show()  # write.csv(\"output/sellers_dim\", header=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"an error was occured while creating seller dimension table \" )\n",
    "    print( \"ERROR: \" , e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6446f46a-f018-4b52-93e0-5aa6421e1fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an error was occured while writing  seller dimension table \n",
      "ERROR:  name 'sellers_dim' is not defined\n"
     ]
    }
   ],
   "source": [
    "#creating pandas and saving it \n",
    "try:\n",
    "    sellers_dim_pandas = sellers_dim.toPandas()\n",
    "    \n",
    "    sellers_dim_pandas.to_csv(f\"{output_dir}/sellers_dim.csv\", index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"an error was occured while writing  seller dimension table \" )\n",
    "    print( \"ERROR: \" , e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38935484-f7f6-48bf-a057-4d0e66a2bbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an error was occured while creating Date dimension table \n",
      "ERROR:  name 'df' is not defined\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create Time Dimension \n",
    "\n",
    "try:\n",
    "    time_df = df.select(\"Date\").dropDuplicates()\n",
    "    \n",
    "    # Extract Year, Quarter, Month, Day_of_Week\n",
    "    from pyspark.sql.functions import  to_date, year, quarter, month, dayofweek\n",
    "    \n",
    "    time_dim = time_df.withColumn(\"YEAR\", year(to_date(col(\"Date\"),\"dd-MMM-yy\"))) \\\n",
    "                      .withColumn(\"QUARTER\", quarter(to_date(col(\"Date\"),\"dd-MMM-yy\"))) \\\n",
    "                      .withColumn(\"MONTH\", month(to_date(col(\"Date\"),\"dd-MMM-yy\"))) \\\n",
    "                      .withColumn(\"DAY_OF_WEEK\", dayofweek(to_date(col(\"Date\"),\"dd-MMM-yy\"))) \\\n",
    "                      .withColumn(\"TIME_DIM_ID\", row_number().over(windowSpec))\n",
    "    \n",
    "                      \n",
    "    # abc =  year(to_date(\"28-aug-11\", \"dd-mmm-yy\"))\n",
    "    # print(abc)\n",
    "    \n",
    "    \n",
    "    time_dim.select.show()  #write.csv(\"output/time_dim\", header=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"an error was occured while creating Date dimension table \" )\n",
    "    print( \"ERROR: \" , e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5761a8b2-bd01-439e-8ade-00f873f85120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an error was occured while saving time dimension table \n",
      "ERROR:  name 'time_dim' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    time_dim_pandas = time_dim.toPandas()\n",
    "    time_dim_pandas.to_csv(f\"{output_dir}/time_dim.csv\", index=False)\n",
    "except Exception as e:\n",
    "    print(\"an error was occured while saving time dimension table \" )\n",
    "    print( \"ERROR: \" , e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f2f7acd-6781-4991-b6f5-a86a8b960594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------+----------------+------------------+----------------+-------------+-------------+-------------+\n",
      "|TRANSACTION_DIM_ID|TRANSACTION_ID|TRANSACTION_DATE|TRANSACTION_AMOUNT|TRANSACTION_TYPE|DISPATCH_DATE|EXPECTED_DATE|DELIVERY_DATE|\n",
      "+------------------+--------------+----------------+------------------+----------------+-------------+-------------+-------------+\n",
      "|                 1|          5223|       12-Aug-11|              1900|             COD|    13-Aug-11|    16-Aug-11|    16-Aug-11|\n",
      "|                 2|          5330|       27-Nov-11|              2100|     NET BANKING|    28-Nov-11|    01-Dec-11|    01-Dec-11|\n",
      "|                 3|          5341|       08-Dec-11|              1800|     CREDIT CARD|    09-Dec-11|    12-Dec-11|    12-Dec-11|\n",
      "|                 4|          5741|       11-Jan-13|               600|             COD|    12-Jan-13|    15-Jan-13|    15-Jan-13|\n",
      "|                 5|          5860|       11-May-13|              8500|          PAYPAL|    11-May-13|    14-May-13|    14-May-13|\n",
      "|                 6|          5995|       22-Sep-13|             16000|             COD|    23-Sep-13|    26-Sep-13|    27-Sep-13|\n",
      "|                 7|          5440|       15-Mar-12|             30000|     NET BANKING|    17-Mar-12|    20-Mar-12|    20-Mar-12|\n",
      "|                 8|          5465|       10-Apr-12|              1600|          PAYPAL|    11-Apr-12|    14-Apr-12|    14-Apr-12|\n",
      "|                 9|          5472|       17-Apr-12|               650|     CREDIT CARD|    18-Apr-12|    21-Apr-12|    21-Apr-12|\n",
      "|                10|          5542|       26-Jun-12|              4800|      DEBIT CARD|    27-Jun-12|    30-Jun-12|    30-Jun-12|\n",
      "|                11|          5974|       01-Sep-13|               350|     NET BANKING|    02-Sep-13|    05-Sep-13|    05-Sep-13|\n",
      "|                12|          5284|       12-Oct-11|              2300|     CREDIT CARD|    13-Oct-11|    16-Oct-11|    16-Oct-11|\n",
      "|                13|          5331|       28-Nov-11|              3800|     CREDIT CARD|    29-Nov-11|    02-Dec-11|    02-Dec-11|\n",
      "|                14|          5500|       15-May-12|              3800|     CREDIT CARD|    16-May-12|    19-May-12|    19-May-12|\n",
      "|                15|          5584|       07-Aug-12|              2000|     NET BANKING|    08-Aug-12|    11-Aug-12|    11-Aug-12|\n",
      "|                16|          5376|       12-Jan-12|              2450|          PAYPAL|    13-Jan-12|    16-Jan-12|    16-Jan-12|\n",
      "|                17|          5749|       19-Jan-13|              1600|          PAYPAL|    20-Jan-13|    23-Jan-13|    23-Jan-13|\n",
      "|                18|          5090|       01-Apr-11|              2900|             COD|    02-Apr-11|    05-Apr-11|    05-Apr-11|\n",
      "|                19|          5367|       03-Jan-12|              4400|     CREDIT CARD|    04-Jan-12|    07-Jan-12|    07-Jan-12|\n",
      "|                20|          5511|       26-May-12|             40500|          PAYPAL|    27-May-12|    30-May-12|    31-May-12|\n",
      "+------------------+--------------+----------------+------------------+----------------+-------------+-------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#  Transaction  Table\n",
    "\n",
    "try:\n",
    "\n",
    "    transaction_df = df.select(\"TRANSACTION_ID\", \"TRANSACTION_DATE\", \"TRANSACTION_AMOUNT\", \n",
    "                               \"TRANSACTION_TYPE\", \"DISPATCH_DATE\", \"EXPECTED_DATE\", \"DELIVERY_DATE\").dropDuplicates()\n",
    "    \n",
    "    transaction_dim = transaction_df.withColumn(\"TRANSACTION_DIM_ID\", row_number().over(windowSpec))\n",
    "    \n",
    "    \n",
    "    transaction_dim.show() \n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"an error was occured while creating transaction dimension table \" )\n",
    "    print( \"ERROR: \" , e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad62cad-8e06-4330-a6b1-361d0c8b23ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an error was occured while writing  trasaction dimension table \n",
      "ERROR:  name 'transaction_dim' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    transaction_dim_pandas   = transaction_dim.toPandas()\n",
    "    \n",
    "    transaction_dim_pandas.to_csv(f\"{output_dir}/transaction_dim.csv\", index=False)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"an error was occured while writing  trasaction dimension table \" )\n",
    "    print( \"ERROR: \" , e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66746259b5598cb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-07T16:52:52.798275Z",
     "start_time": "2024-10-07T16:52:52.788101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------+----------+-----------+---------+------------------+---------------------+\n",
      "|FACT_ID|TIME_DIM_ID|TRANSACTION_ID|PRODUCT_ID|CUSTOMER_ID|SELLER_ID|PRODUCT_COST_PRICE|PRODUCT_SELLING_PRICE|\n",
      "+-------+-----------+--------------+----------+-----------+---------+------------------+---------------------+\n",
      "|      1|        917|          5282|      3026|     100098|   200071|             38000|                41000|\n",
      "|      2|        278|          5303|      3058|     100031|   200043|              1200|                 1100|\n",
      "|      3|        794|          5582|      3080|     100025|   200003|              1900|                 2000|\n",
      "|      4|        683|          5031|      3093|     100021|   200019|             47000|                52000|\n",
      "|      5|        829|          5676|      3003|     100011|   200042|              6500|                 6750|\n",
      "|      6|        163|          5252|      3024|     100079|   200096|              6000|                 6200|\n",
      "|      7|        324|          5536|      3026|     100001|   200095|             38000|                41000|\n",
      "|      8|        994|          5724|      3094|     100092|   200019|               560|                  750|\n",
      "|      9|        692|          5888|      3053|     100052|   200090|              1400|                 1350|\n",
      "|     10|        552|          5927|      3034|     100015|   200097|              1600|                 1800|\n",
      "|     11|        716|          5083|      3030|     100087|   200077|             16000|                18000|\n",
      "|     12|        924|          5122|      3006|     100044|   200068|             13000|                13000|\n",
      "|     13|        451|          5473|      3095|     100043|   200073|              1800|                 1950|\n",
      "|     14|        617|          5502|      3099|     100009|   200095|              8000|                 8000|\n",
      "|     15|        659|          5521|      3054|     100017|   200075|               400|                  600|\n",
      "|     16|        494|          5321|      3020|     100090|   200057|               800|                  900|\n",
      "|     17|        427|          5452|      3007|     100015|   200070|             40100|                40500|\n",
      "|     18|        643|          5051|      3094|     100073|   200009|               560|                  750|\n",
      "|     19|        185|          5106|      3024|     100024|   200002|              6000|                 6200|\n",
      "|     20|        251|          5156|      3027|     100083|   200031|               500|                  650|\n",
      "+-------+-----------+--------------+----------+-----------+---------+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Fact Table (Inventory)\n",
    "try:\n",
    "    inventory_fact_df = df.select(\"DATE\" ,\"TRANSACTION_ID\", \"PRODUCT_ID\" , \"CUSTOMER_ID\", \n",
    "                               \"SELLER_ID\",\"PRODUCT_COST_PRICE\",\"PRODUCT_SELLING_PRICE\").dropDuplicates()\n",
    "    inventory_fact_df = inventory_fact_df.join(time_dim, \"DATE\", \"inner\")\n",
    "    \n",
    "    inventory_fact = inventory_fact_df.withColumn(\"FACT_ID\", row_number().over(windowSpec))\n",
    "    \n",
    "    inventory_fact.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"an error was occured while creating inventory fact table \" )\n",
    "    print( \"ERROR: \" , e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f3a3665-8d50-4de3-a2a3-c61f10b94762",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    inventory_fact_pandas  = inventory_fact.select(\"FACT_ID\", \"TIME_DIM_ID\", \"TRANSACTION_ID\", \n",
    "                          \"PRODUCT_ID\", \"CUSTOMER_ID\", \"SELLER_ID\", \n",
    "                          \"PRODUCT_COST_PRICE\", \"PRODUCT_SELLING_PRICE\") \\\n",
    "                          .toPandas()\n",
    "    \n",
    "    inventory_fact_pandas.to_csv(f\"output/inventory_fact.csv\", index=False)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"an error was occured while saving invenotry fact table \" )\n",
    "    print( \"ERROR: \" , e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ef8cca0-1bc6-4bb3-b528-6835a8ade0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
